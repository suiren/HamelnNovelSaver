#!/usr/bin/env python3
"""
ç·Šæ€¥ãƒŠãƒ“ã‚²ãƒ¼ã‚·ãƒ§ãƒ³ãƒªãƒ³ã‚¯ä¿®æ­£ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
ç›®æ¬¡ãƒªãƒ³ã‚¯ã¨æ¬¡ã®è©±ãƒªãƒ³ã‚¯ã‚’å®Œå…¨ã«ä¿®æ­£ã™ã‚‹
"""
import os
import sys
from bs4 import BeautifulSoup

def fix_all_navigation_links():
    print("=== ç·Šæ€¥ãƒŠãƒ“ã‚²ãƒ¼ã‚·ãƒ§ãƒ³ãƒªãƒ³ã‚¯ä¿®æ­£é–‹å§‹ ===")
    
    base_dir = "/home/suiren/ClaudeTest/saved_novels/ãƒ€ã‚¦ãƒŠãƒ¼å¥³ç¥ã®ã‚¢ã‚¯ã‚¢æ§˜"
    
    # å®Ÿéš›ã®ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§
    files = [
        "ãƒ€ã‚¦ãƒŠãƒ¼å¥³ç¥ã®ã‚¢ã‚¯ã‚¢æ§˜ - åºç« ã€€å½¼ã¨å½¼å¥³ã®å‡ºä¼šã„ - ãƒãƒ¼ãƒ¡ãƒ«ãƒ³.html",
        "ãƒ€ã‚¦ãƒŠãƒ¼å¥³ç¥ã®ã‚¢ã‚¯ã‚¢æ§˜ - ç¬¬ä¸€è©±ã€€å¥³ç¥ã€é™ã‚Šç«‹ã¤ã€‚ãã—ã¦ã‚„ã‚‰ã‹ã™ã€‚ - ãƒãƒ¼ãƒ¡ãƒ«ãƒ³.html", 
        "ãƒ€ã‚¦ãƒŠãƒ¼å¥³ç¥ã®ã‚¢ã‚¯ã‚¢æ§˜ - ç¬¬äºŒè©±ã€€ä»Šæ—¥ã‚’ä½•ã¨ã‹é ‘å¼µã‚‹ãã„ï¼ - ãƒãƒ¼ãƒ¡ãƒ«ãƒ³.html",
        "ãƒ€ã‚¦ãƒŠãƒ¼å¥³ç¥ã®ã‚¢ã‚¯ã‚¢æ§˜ - ç›®æ¬¡.html"
    ]
    
    # ãƒ•ã‚¡ã‚¤ãƒ«é †åºãƒãƒƒãƒ”ãƒ³ã‚°
    navigation_mapping = {
        "ãƒ€ã‚¦ãƒŠãƒ¼å¥³ç¥ã®ã‚¢ã‚¯ã‚¢æ§˜ - åºç« ã€€å½¼ã¨å½¼å¥³ã®å‡ºä¼šã„ - ãƒãƒ¼ãƒ¡ãƒ«ãƒ³.html": {
            "next": "ãƒ€ã‚¦ãƒŠãƒ¼å¥³ç¥ã®ã‚¢ã‚¯ã‚¢æ§˜ - ç¬¬ä¸€è©±ã€€å¥³ç¥ã€é™ã‚Šç«‹ã¤ã€‚ãã—ã¦ã‚„ã‚‰ã‹ã™ã€‚ - ãƒãƒ¼ãƒ¡ãƒ«ãƒ³.html"
        },
        "ãƒ€ã‚¦ãƒŠãƒ¼å¥³ç¥ã®ã‚¢ã‚¯ã‚¢æ§˜ - ç¬¬ä¸€è©±ã€€å¥³ç¥ã€é™ã‚Šç«‹ã¤ã€‚ãã—ã¦ã‚„ã‚‰ã‹ã™ã€‚ - ãƒãƒ¼ãƒ¡ãƒ«ãƒ³.html": {
            "prev": "ãƒ€ã‚¦ãƒŠãƒ¼å¥³ç¥ã®ã‚¢ã‚¯ã‚¢æ§˜ - åºç« ã€€å½¼ã¨å½¼å¥³ã®å‡ºä¼šã„ - ãƒãƒ¼ãƒ¡ãƒ«ãƒ³.html",
            "next": "ãƒ€ã‚¦ãƒŠãƒ¼å¥³ç¥ã®ã‚¢ã‚¯ã‚¢æ§˜ - ç¬¬äºŒè©±ã€€ä»Šæ—¥ã‚’ä½•ã¨ã‹é ‘å¼µã‚‹ãã„ï¼ - ãƒãƒ¼ãƒ¡ãƒ«ãƒ³.html"
        },
        "ãƒ€ã‚¦ãƒŠãƒ¼å¥³ç¥ã®ã‚¢ã‚¯ã‚¢æ§˜ - ç¬¬äºŒè©±ã€€ä»Šæ—¥ã‚’ä½•ã¨ã‹é ‘å¼µã‚‹ãã„ï¼ - ãƒãƒ¼ãƒ¡ãƒ«ãƒ³.html": {
            "prev": "ãƒ€ã‚¦ãƒŠãƒ¼å¥³ç¥ã®ã‚¢ã‚¯ã‚¢æ§˜ - ç¬¬ä¸€è©±ã€€å¥³ç¥ã€é™ã‚Šç«‹ã¤ã€‚ãã—ã¦ã‚„ã‚‰ã‹ã™ã€‚ - ãƒãƒ¼ãƒ¡ãƒ«ãƒ³.html"
        }
    }
    
    index_file = "ãƒ€ã‚¦ãƒŠãƒ¼å¥³ç¥ã®ã‚¢ã‚¯ã‚¢æ§˜ - ç›®æ¬¡.html"
    
    for filename in files:
        file_path = os.path.join(base_dir, filename)
        if not os.path.exists(file_path):
            print(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ã¾ã›ã‚“: {filename}")
            continue
            
        print(f"\nğŸ”§ ä¿®æ­£ä¸­: {filename}")
        
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        soup = BeautifulSoup(content, 'html.parser')
        modified = False
        
        # 1. ç›®æ¬¡ãƒªãƒ³ã‚¯ã‚’å…¨ã¦ä¿®æ­£
        index_patterns = [
            lambda tag: tag.name == 'a' and tag.get('href') == 'https://syosetu.org/novel/378070/',
            lambda tag: tag.name == 'a' and tag.get('href') and '/novel/378070/' in tag.get('href') and tag.get('href').endswith('/'),
            lambda tag: tag.name == 'a' and 'ç›®æ¬¡' in tag.get_text() and 'syosetu.org' in str(tag.get('href', ''))
        ]
        
        for pattern in index_patterns:
            links = soup.find_all(pattern)
            for link in links:
                if link.get('href') != index_file:
                    print(f"  ğŸ“‚ ç›®æ¬¡ãƒªãƒ³ã‚¯ä¿®æ­£: {link.get('href')} -> {index_file}")
                    link['href'] = index_file
                    modified = True
        
        # 2. æ¬¡ã®è©±ãƒ»å‰ã®è©±ãƒªãƒ³ã‚¯ã‚’ä¿®æ­£
        if filename in navigation_mapping:
            nav_info = navigation_mapping[filename]
            
            # æ¬¡ã®è©±ãƒªãƒ³ã‚¯
            if 'next' in nav_info:
                next_patterns = [
                    lambda tag: tag.name == 'a' and 'æ¬¡ã®è©±' in tag.get_text(),
                    lambda tag: tag.name == 'a' and tag.get('class') and 'next_page_link' in tag.get('class'),
                    lambda tag: tag.name == 'a' and tag.get('href') and (tag.get('href').startswith('ç¬¬') and tag.get('href').endswith('è©±.html'))
                ]
                
                for pattern in next_patterns:
                    links = soup.find_all(pattern)
                    for link in links:
                        if link.get('href') != nav_info['next']:
                            print(f"  â–¶ï¸ æ¬¡ã®è©±ãƒªãƒ³ã‚¯ä¿®æ­£: {link.get('href')} -> {nav_info['next']}")
                            link['href'] = nav_info['next']
                            modified = True
            
            # å‰ã®è©±ãƒªãƒ³ã‚¯
            if 'prev' in nav_info:
                prev_patterns = [
                    lambda tag: tag.name == 'a' and 'å‰ã®è©±' in tag.get_text()
                ]
                
                for pattern in prev_patterns:
                    links = soup.find_all(pattern)
                    for link in links:
                        if link.get('href') != nav_info['prev']:
                            print(f"  â—€ï¸ å‰ã®è©±ãƒªãƒ³ã‚¯ä¿®æ­£: {link.get('href')} -> {nav_info['prev']}")
                            link['href'] = nav_info['prev']
                            modified = True
        
        # 3. ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜
        if modified:
            with open(file_path, 'w', encoding='utf-8') as f:
                f.write(str(soup))
            print(f"  âœ… ä¿å­˜å®Œäº†")
        else:
            print(f"  â„¹ï¸ ä¿®æ­£ä¸è¦")
    
    print("\n=== ç·Šæ€¥ãƒŠãƒ“ã‚²ãƒ¼ã‚·ãƒ§ãƒ³ãƒªãƒ³ã‚¯ä¿®æ­£å®Œäº† ===")

if __name__ == "__main__":
    fix_all_navigation_links()