#!/usr/bin/env python3
"""
ãƒŠãƒ“ã‚²ãƒ¼ã‚·ãƒ§ãƒ³ãƒªãƒ³ã‚¯ä¿®æ­£ã®ãƒ†ã‚¹ãƒˆ
"""
import os
from bs4 import BeautifulSoup

def test_navigation_fix():
    print("=== ãƒŠãƒ“ã‚²ãƒ¼ã‚·ãƒ§ãƒ³ãƒªãƒ³ã‚¯ä¿®æ­£ãƒ†ã‚¹ãƒˆ ===")
    
    file_path = "/home/suiren/ClaudeTest/saved_novels/ãƒ€ã‚¦ãƒŠãƒ¼å¥³ç¥ã®ã‚¢ã‚¯ã‚¢æ§˜/ãƒ€ã‚¦ãƒŠãƒ¼å¥³ç¥ã®ã‚¢ã‚¯ã‚¢æ§˜ - ç¬¬äºŒè©±ã€€ä»Šæ—¥ã‚’ä½•ã¨ã‹é ‘å¼µã‚‹ãã„ï¼ - ãƒãƒ¼ãƒ¡ãƒ«ãƒ³.html"
    
    if not os.path.exists(file_path):
        print(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ã¾ã›ã‚“: {file_path}")
        return
    
    print(f"ğŸ“‚ ãƒ†ã‚¹ãƒˆå¯¾è±¡: {os.path.basename(file_path)}")
    
    # ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿
    with open(file_path, 'r', encoding='utf-8') as f:
        content = f.read()
    
    soup = BeautifulSoup(content, 'html.parser')
    
    # ç©ºãƒªãƒ³ã‚¯ã®æ¤œå‡ºã¨ä¿®æ­£å‰ã®çŠ¶æ…‹ç¢ºèª
    print("\nğŸ” ä¿®æ­£å‰ã®çŠ¶æ…‹:")
    empty_links = soup.find_all('a', href='#')
    for i, link in enumerate(empty_links):
        print(f"  ç©ºãƒªãƒ³ã‚¯ {i+1}: href='{link.get('href')}' text='{link.get_text().strip()}'")
    
    # ä¿®æ­£é©ç”¨
    print("\nğŸ”§ ä¿®æ­£é©ç”¨ä¸­:")
    modified = False
    for link in empty_links:
        link_text = link.get_text().strip()
        if link_text == 'Ã—' or 'æ¬¡ã®è©±' in link_text:
            print(f"  ğŸ“ ä¿®æ­£å¯¾è±¡: '{link_text}'")
            link['href'] = 'javascript:void(0);'
            link.string = 'æœ€çµ‚è©±'
            link['class'] = link.get('class', []) + ['disabled']
            link['style'] = 'color: #999; cursor: not-allowed; text-decoration: none;'
            print(f"  âœ… ä¿®æ­£å®Œäº†: href='javascript:void(0);' text='æœ€çµ‚è©±'")
            modified = True
    
    if modified:
        # ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
        with open(file_path, 'w', encoding='utf-8') as f:
            f.write(str(soup))
        print(f"\nğŸ’¾ ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜å®Œäº†")
    else:
        print(f"\n â„¹ï¸ ä¿®æ­£å¯¾è±¡ãªã—")
    
    # ä¿®æ­£å¾Œã®ç¢ºèª
    print("\nâœ… ä¿®æ­£å¾Œã®çŠ¶æ…‹:")
    empty_links_after = soup.find_all('a', href='javascript:void(0);')
    for i, link in enumerate(empty_links_after):
        print(f"  ç„¡åŠ¹åŒ–ãƒªãƒ³ã‚¯ {i+1}: href='{link.get('href')}' text='{link.get_text().strip()}'")
    
    print("\n=== ãƒ†ã‚¹ãƒˆå®Œäº† ===")

if __name__ == "__main__":
    test_navigation_fix()